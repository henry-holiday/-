import scrapy

class FsPagesSpider(scrapy.Spider):
    name = "scrapy_multiple_pages_test"
    allowed_domains = ["www.fsgykg.com"]
    start_urls = [
        "https://www.fsgykg.com/index/Page/index.html?index%2FPage%2Findex_html=&cate=42&page=1",
        "https://www.fsgykg.com/index/Page/index.html?index%2FPage%2Findex_html=&cate=42&page=2"
    ]

    def parse(self, response):
        # add the https://www.fsgykg.com/ before the href links
        articles = response.css('div.bottom a::attr(href)').getall()
        articles = [response.urljoin(url) for url in articles]
        print(articles)
        # Follow the links to the articles
        for article in articles:
            yield scrapy.Request(url=article, callback=self.parse_article)

    def parse_article(self, response):
        # Extract the text content from the article
        text_content = response.css('span[style*="font-family: 仿宋_GB2312;"]::text').getall()
        yield {
            'body_text': text_content,
        }
# https://www.fsgykg.com/index/Article/info.html?cate=44&id=3109
# https://www.fsgykg.com/index/Article/info.html?cate=44&id=2580
# https://www.fsgykg.com/index/Article/info.html?cate=44&id=2582
# https://www.fsgykg.com/index/Article/info.html?cate=44&id=3323
