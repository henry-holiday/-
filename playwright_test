import asyncio
from playwright.async_api import async_playwright
from fake_useragent import UserAgent
import logging

# Create a UserAgent object
ua = UserAgent()
# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

async def scrape_website(page, url):
    # Try to go to the url
    try:
        await page.goto(url)
        while True:
            data = await page.content()
            print(data)
            # Scroll to the bottom of the page
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await asyncio.sleep(5)  # Set delay time to 5 seconds
            # Click the "Next" button using JavaScript
            clicked = await page.evaluate('''() => {
                const nextButton = document.querySelector('li.next > a');
                if (nextButton) {
                    nextButton.click();
                    return true;
                }
                return false;
            }''')
            if not clicked:
                break
            # Set the user-agent header for the page
            user_agent = ua.random
            await page.set_extra_http_headers({'User-Agent': user_agent})
            # Log the user-agent string
            logging.info(f'Using user-agent: {user_agent}')
            await page.wait_for_load_state()
    except Exception as e:
        # Handle any errors or exceptions
        logging.error(f'An error occurred while scraping {url}: {e}')

async def scrape_data():
    async with async_playwright() as p:
        browser = await p.firefox.launch(headless=False)
        page1 = await browser.new_page()
        page2 = await browser.new_page()

        # Scrape bookstoscrape.com and quotes.toscrape.com simultaneously
        await asyncio.gather(
            scrape_website(page1, 'http://books.toscrape.com/'),
            scrape_website(page2, 'http://quotes.toscrape.com/')
        )

        await browser.close()

# Run the function
asyncio.run(scrape_data())
